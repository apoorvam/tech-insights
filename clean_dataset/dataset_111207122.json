{
    "url": "https://levelup.gitconnected.com/the-regular-expression-denial-of-service-redos-cheat-sheet-a78d0ed7d865",
    "text": "Introduction\r\nThis post is intended as a \u201Ctechnical two-pager\u201D to summarize a security vulnerability called Regex-based Denial of Service (AKA Regex DoS, ReDoS). There are a variety of write-ups about ReDoS, but I\u2019m not aware of a good one-stop-shop with a higher-level treatment of all aspects of the subject. I have included links at the end to more detailed treatments.\r\nI have used headings liberally to help you navigate to your issue.\r\nWhat is a regular expression?\r\nA regular expression (regex) is a tool that your engineering team uses to manipulate strings. They probably use it to impose some kind of order on unstructured input, e.g. when handling user data or working with log files.\r\nA regex is a pattern language for strings. You can use regexes to ask questions like \u201CDoes this string look like an email?\u201D.\r\nRegexes are built into most programming languages and are evaluated by a regex engine that takes a string and a regex (string pattern) and decides whether the string matches the pattern.\r\nWhat is Regex DoS?\r\nReDoS is a performance problem. It can lead to service outages either through an external denial of service attack or a combination of \u201Caccidental but non-malicious\u201D factors (see the confluence of errors at Stack Overflow).\r\nThe core premise of ReDoS is that some regular expressions \u2014I\u2019ll call these ReDoS regexes \u2014 can take an extremely long time to match (or mismatch) some strings. This would be fine if the inputs in question were trustworthy, but regular expressions are commonly applied to user-controllable input, for example to confirm that a web form actually contains an email address and a phone number.\r\nThis long matching time can divert computational resources (CPU time, worker threads) from legitimate clients to a few long-running regex matches. This can lead to problems in two ways:\r\nIf an attacker can identify input on which your regexes run slowly, they can send you those inputs and bring down your service (or increase your cloud spend).\r\nIf your regexes are applied to new classes of input (e.g. your service receives 10x more traffic one day, or you deploy your software in a new country), the new input may uncover previously-hidden performance problems, and likewise affect your service.\r\nShould I worry about ReDoS?\r\nRegexes are used all over the system stack (see picture), and so software all over the system stack can be a source of ReDoS. Here are the conditions you should check for:\r\nYou use a ReDoS regex on untrusted input. I\u2019ll talk about this in the next section.\r\nYour regex engine uses a slow regex matching algorithm. This is the case for the regex engines built into most programming language runtimes \u2014 this includes Java, JavaScript (various flavors) and Node.js, C#/.NET, Ruby, Python, Perl, and PHP. On the safe side, Go and Rust both use fast regex engines, and Google\u2019s RE2 library is fast as well.\r\nYour regex engine has no resource usage limit. A few regex engines offer limits, including Perl, PHP, and C#/.NET. Among these, only time-based limits like those offered by the .NET regex engine are useful. If you are using regexes in .NET, use the APIs with timeouts!\r\nIf you operate a web server, you should be particularly cautious if you are using Node.js or other event-driven frameworks that permit one expensive request to block other requests. Read more about this here and here.\r\nHow can I tell if I have a ReDoS regex?\r\nI maintain a project with an ensemble of good automatic checkers here. I also maintain the safe-regex project, though at the moment it will only detect a small proportion of problematic regexes.\r\nIf you want to find a ReDoS regex by hand, the basic rule of thumb is to avoid ambiguity \u2014 cases where the regex engine could make two different choices and end up at the same point (I cover this in the appendix below, see heading \u201CWhat makes ReDoS regexes so slow?\u201D).\r\nAmbiguity commonly occurs as the result of ORs and quantifiers (*, +, {5,10}, etc.). Some ambiguity is worse than others \u2014 (a|a) is ambiguous, but only a little bit. (a|a)* is exponentially ambiguous because the number of paths doubles for every additional Frankly, this can be hard to do with your eyes. I have looked at hundreds of ReDoS regexes and still have trouble with particularly tricky examples. But here are some rules of thumb:\r\nNested quantifiers can be exponentially dangerous \u2014 e.g. (a*)*. Check if you can \u201Cget back around\u201D to the inner quantifier by taking the outer quantifier instead.\r\nQuantifying a disjunction can be exponentially dangerous \u2014 e.g. (a|a)*. Check if any strings can be matched by two different paths through the disjunction.\r\nConcatenated quantifiers can be polynomially dangerous \u2014 e.g. abc.*def.*. Can some string be matched by the first quantifier, and the intervening pattern, and by the next quantifier? These are the most common kind of ReDos regex, because many regexes contain a .* or a [\\s\\S]* (i.e. a catch-all quantifier). Every extra reachable quantifier multiplies the cost.\r\nAs a special case of the previous one, if you are performing a partial match, e.g. \u201Csearch this free-form text for an email address\u201D, then the regex engine adds an implicit .*? to the beginning of your regex.\r\nHow do I fix ReDoS in my software?\r\nYou can address ReDoS by invalidating any of the ReDoS conditions described above.\r\nYou can convert your ReDoS regex into either a safe regex or alternative string logic.\r\nYou can sanitize the input.\r\nYou can use a faster regex engine.\r\nYou can use your regex engine\u2019s resource limit (only applicable in C#/.NET).\r\nOption 1: Use a safe regex (or alternative string logic)\r\nIf alternative string logic is viable, that\u2019s a fine approach. Some APIs only take regexes, though, so you may need to refactor your regex into a safe variation.\r\nAs a general rule, your goal is to remove the problematic ambiguity in your regex.\r\nI usually identify such ambiguity using a visualization tool like regexper.\r\nNext, I eliminate the ambiguity. This might be done in a few ways. For example, you might change what you are quantifying \u2014 e.g. from the email regex .+@.+ to one like [^@]+@.+ . Then the intervening \u201C@\u201D becomes a guard between the two quantifiers. Or you could shift optionality, e.g. converting the number regex \\d+\\.?\\d+ to the equivalent \\d+(\\.\\d+)?. If you are using capture groups in your code, you might need to introduce multiple layers of regexes, e.g. a coarse-grained one and then a fine-grained one.\r\nThen, I confirm that the previously-problematic input is now safe (e.g. using Regex 101), and check that I haven\u2019t added new ambiguity in the process.\r\nFinally, I check the regex against my test suite of inputs to confirm that I haven\u2019t changed its string language (or at least, not in a problematic way).\r\nOption 2: Sanitize the input\r\nThe easiest sanitization you can apply is to test the length of the input before feeding it to a regex. If legitimate input is short, then enforce that length limit BEFORE and not AFTER the regex check. This is helpful for avoiding ReDoS through polynomial behavior (e.g. the common pattern of abc.*def.*).\r\nThere are more sophisticated sanitizations, but I wouldn\u2019t trust myself to do them properly. If legitimate input is long, don\u2019t follow this approach. If your regex is exponential, then 30 characters is \u201Ctoo long\u201D. Most slow regexes are quadratic (they use .* too freely), for which you will see millisecond-to-second matching times for inputs of 1000\u20135000 characters.\r\nOption 3: Use a faster regex engine\r\nAt the moment, the most widely available fast regex engine is Russ Cox/Google\u2019s RE2 regex engine. It has bindings for most programming languages. You can introduce it as a dependency and evaluate your regex queries there. You could also try Geoff Longdale/Intel\u2019s HyperScan engine.\r\nPros: Guaranteed to run fast.\r\nCons:\r\nFaster engines may not support advanced features, most notably backreferences and lookaround assertions.\r\nCertain regexes may exhibit slightly different matching behavior. This can be hard to detect, so this is a good time to enhance your test suite. You could also try an input generator like Microsoft\u2019s Rex project (an input generator ensemble is here).\r\nOption 4: Use a resource limit\r\nIf you\u2019re working in C#/.NET, the best practice is to always use the timeout-based API for your regex matches.\r\nIn other programming languages, you can \u201Croll your own\u201D version of this using threads and timers.\r\nWhy aren\u2019t there websites with tools for this?\r\nIf you have website-building experience and want to help out, please drop me a line. I have loads of ideas.\r\n",
    "title": "The Regular Expression Denial of Service (ReDoS) cheat-sheet"
} 